{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smv-manovihar/MechanicAI/blob/main/backend/JanathaGarage_Server.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "OaffPlQzIGSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing necessary modules"
      ],
      "metadata": {
        "id": "L62zQurrIJtK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sF591dADMLy"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install -y pciutils\n",
        "!curl -fsSL https://ollama.com/install.sh | sh #installing Ollama\n",
        "!pip install pyngrok flask-ngrok flask-cors pymongo sentence_transformers\n",
        "!ngrok authtoken 2jAeEXz0n15BRb4Vmjzh1OA1aw4_2EMyvpRPZ4TQymWyPhgKB\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating an Ollama instance in the environment"
      ],
      "metadata": {
        "id": "_YGZQ27fIX3U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3psvlX5-GP0_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import threading\n",
        "import subprocess\n",
        "import requests\n",
        "import json\n",
        "def ollama():\n",
        "    os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
        "    os.environ['OLLAMA_ORIGINS'] = '*'\n",
        "    subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "ollama_thread = threading.Thread(target=ollama)\n",
        "ollama_thread.start()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading Llama 3.1 8B"
      ],
      "metadata": {
        "id": "CbpOWkiWIegn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfRfHvsSqNf7"
      },
      "outputs": [],
      "source": [
        "!ollama pull llama3.1:8b\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing LightRAG pytorch library"
      ],
      "metadata": {
        "id": "Rs6Gm2ZkIpI7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjFr470eDRWb"
      },
      "outputs": [],
      "source": [
        "!pip install -U lightrag[ollama]\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozc7mJ6DDRaL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "import threading\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok\n",
        "from lightrag.core.generator import Generator\n",
        "from lightrag.core.component import Component\n",
        "from lightrag.core.model_client import ModelClient\n",
        "from lightrag.components.model_client import OllamaClient\n",
        "import time\n",
        "from pymongo import MongoClient\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from google.colab import userdata\n",
        "from lightrag.components.model_client import OllamaClient\n",
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuring Llama"
      ],
      "metadata": {
        "id": "C12UhFNoJNyx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41IRQpg7YPPm"
      },
      "outputs": [],
      "source": [
        "qa_template = r\"\"\"<SYS>You are Repair Assistant who is an automotive expert. Your job is to assist users with car repairs, vehicle maintenance. Provide detailed and relevant information while following the structured response format below.\n",
        "\n",
        "Response Guidelines:\n",
        "\n",
        "Context Usage: Use the provided context to inform your response, USER wont be having access for this context DO NOT Recommend USER to refer the sections in the context, use it to impprove your response quality.\n",
        "\n",
        "Follow up requests: Do not encourage follow up for the prompts that are not related to car repairs. You can encourage follow up prompts when the user is on repair-related only.\n",
        "\n",
        "Scope: Only respond to queries related to car repairs, vehicle maintenance. Politely refuse if the query is unrelated or unclear. Do not answer about trips or food related or any other unrelated topics.\n",
        "\n",
        "Car parts explanation: Don't hesitate to explain if user asks what a certain part is. The context might not be useful in this case.\n",
        "\n",
        "Response Structure:\n",
        "\n",
        "  Diagnosis: Briefly explain the repair or the possible cause of the problem.\n",
        "  Instructions: Provide a step-by-step and detailed guide.\n",
        "  Tools Required: List all necessary tools.\n",
        "  Parts Replacement: Specify any parts that need replacement.\n",
        "  Safety Tips: Include key safety precautions.\n",
        "  Invalid Queries: Politely refuse to answer if the query is not relevant. your response for these type of queries should be maximum one sentence.\n",
        "\n",
        "</SYS>\n",
        "Context:\n",
        "      {{context}}\n",
        "\n",
        "#### User: {{input_str}}\n",
        "You:\"\"\"\n",
        "\n",
        "\n",
        "class LlamaGen:\n",
        "    def __init__(self, model_client, model_kwargs):\n",
        "        self.generator = Generator(model_client=model_client, model_kwargs=model_kwargs, template=qa_template)\n",
        "\n",
        "    def call(self, input, context):\n",
        "        response = self.generator.call({\"input_str\": str(input), \"context\": str(context)})\n",
        "        return response.data if hasattr(response, 'data') else str(response)  # Ensure response is a string\n",
        "\n",
        "    async def acall(self, input: dict, context: str) -> str:\n",
        "        return await self.generator.acall({\"input_str\": str(input), \"context\": str(context)})\n",
        "\n",
        "title_temp=r\"\"\"<SYS>\n",
        "      You are specialized in creating short summarized titles for a given text. Do not use quotes for the title\n",
        "      Give only the title as the output as below:\n",
        "      {generated title}\n",
        "</SYS>\n",
        "    Create a shortest title possible for the following text:\n",
        "    {{input_str}}\n",
        "You:\"\"\"\n",
        "\n",
        "class TitleGenertor:\n",
        "    def __init__(self, model_client, model_kwargs):\n",
        "        self.generator = Generator(model_client=model_client, model_kwargs=model_kwargs, template=title_temp)\n",
        "\n",
        "    def call(self, input):\n",
        "        response = self.generator.call({\"input_str\": str(input)})\n",
        "        return response.data if hasattr(response, 'data') else str(response)  # Ensure response is a string\n",
        "\n",
        "    async def acall(self, input: dict) -> str:\n",
        "        return await self.generator.acall({\"input_str\": str(input)})\n",
        "\n",
        "llm_model = {\n",
        "    \"model_client\": OllamaClient(),\n",
        "    \"model_kwargs\": {\"model\": \"llama3.1:8b\"},\n",
        "}\n",
        "qa = LlamaGen(**llm_model)\n",
        "title_gen = TitleGenertor(**llm_model);\n",
        "\n",
        "# prompt = \"my car is not starting\"\n",
        "# context = get_context(prompt)\n",
        "# print(context)\n",
        "# output = qa.call(prompt, context)\n",
        "# display(Markdown(f\"**Answer:**\"))\n",
        "# display(Markdown(f\"{output.data}\"))\n",
        "\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG"
      ],
      "metadata": {
        "id": "ftuuDqDyJWcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = MongoClient(\"mongodb+srv://DataPuller:janathagarage_read@janathagarage.sxw1j.mongodb.net/\")\n",
        "db = client['MechanicAI']\n",
        "collection = db['Hatchback']\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "\n",
        "def semantic_search(query, top_k=5):\n",
        "    \"\"\"\n",
        "    Perform semantic search on MongoDB-stored embeddings.\n",
        "\n",
        "    Parameters:\n",
        "    - query (str): The search query.\n",
        "    - top_k (int): Number of top similar chunks to retrieve.\n",
        "\n",
        "    Returns:\n",
        "    - List of dictionaries containing 'score' and 'text' of top K chunks.\n",
        "    \"\"\"\n",
        "    # Step 1: Encode the query\n",
        "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
        "\n",
        "    # Step 2: Fetch all documents with embeddings\n",
        "    cursor = collection.find({}, {'text': 1, 'embeddings': 1})  # Adjust fields if necessary\n",
        "\n",
        "    # Prepare lists to store texts and embeddings\n",
        "    texts = []\n",
        "    embeddings = []\n",
        "\n",
        "    for doc in cursor:\n",
        "        texts.append(doc['text'])\n",
        "        embeddings.append(doc['embeddings'])\n",
        "\n",
        "    # Convert list of embeddings to a tensor and move to the same device as query_embedding\n",
        "    corpus_embeddings = torch.tensor(embeddings).to(query_embedding.device) # Move to the device of query_embedding\n",
        "\n",
        "    # Step 3: Compute cosine similarity between query and all embeddings\n",
        "    cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "\n",
        "    # Step 4: Retrieve the top K chunks with highest similarity scores\n",
        "    top_results = torch.topk(cos_scores, k=top_k)\n",
        "\n",
        "    # Collect the top K results\n",
        "    top_chunks = []\n",
        "    for score, idx in zip(top_results.values, top_results.indices):\n",
        "        top_chunks.append({\n",
        "            'score': score.item(),\n",
        "            'text': texts[idx]\n",
        "        })\n",
        "\n",
        "    return top_chunks\n",
        "\n",
        "def get_context(query):\n",
        "    # query_embedding = get_query_embedding(query)  # Get the embedding for the query\n",
        "    top_k_sections = semantic_search(query, top_k=2)\n",
        "    if  top_k_sections[0][\"score\"] < 0.3:\n",
        "      return \"\"\n",
        "    context = \" \".join([section[\"text\"] for section in top_k_sections])\n",
        "    return context"
      ],
      "metadata": {
        "id": "f4H6VL9-JVPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JuOcSHSDRdJ",
        "outputId": "18c19514-66c5-49cc-fa93-a184ed6a2d99"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Oct/2024 10:14:55] \"POST /chat HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Oct/2024 10:15:47] \"POST /chat HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Oct/2024 10:17:52] \"POST /chat HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Oct/2024 10:18:27] \"POST /chat HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Oct/2024 10:22:47] \"POST /chat HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Oct/2024 10:26:16] \"POST /chat HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "# ngrok.set_auth_token(\"2nVyRD5l0Q6YkY50VvBdlApRrp9_5n4F6k61SyZLpQoWDF2fF\")\n",
        "# public_url = ngrok.connect(5000)\n",
        "# print(f\" * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:5000\\\"\")\n",
        "\n",
        "\n",
        "# Setup Flask app\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "#run_with_ngrok(app)\n",
        "@app.route('/chat', methods=['POST'])\n",
        "def chat():\n",
        "    data = request.json\n",
        "    user_prompt = data['prompt']\n",
        "    new = data['new']\n",
        "    context = get_context(user_prompt)\n",
        "    output = qa.call(user_prompt, context)\n",
        "    if new:\n",
        "      title = title_gen.call(\"User:\\n\"+user_prompt+\"Assitant:\\n\"+output)\n",
        "      return jsonify({'response': output, 'title': title})\n",
        "    # Remove Markdown asterisks\n",
        "    clean_output = output.replace(\"**\", \"\").replace(\"*\", \"\")\n",
        "    return jsonify({'response': clean_output})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Set up ngrok with custom domain\n",
        "    get_ipython().system_raw('ngrok http --domain=koi-wanted-mayfly.ngrok-free.app 5000 &')\n",
        "    app.run(port=5000)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0WsoM8IEf-m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d84e5dd9-ddd9-459e-80fb-4841db43886a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Helping With Car Questions'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "title_gen.call(\"Hello! It looks like we've just started our conversation, and I'm excited to help with any car-related questions or concerns you might have. However, I'd love it if you could give me a bit more context about what brings you here today - is there an issue with your vehicle that you're trying to troubleshoot?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwZhRhUOEgLe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "QicEAe7yEgOe",
        "outputId": "6d4d0f7b-7d9c-4b1c-e709-676b93b21d4e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:lightrag.core.generator:Error calling the model: [Errno 111] Connection refused\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "terminal connection Retighten or replace. Loose grounding cable connection Retighten.Fuse set loose or blown off Tighten or replace.Poor contacting action of ignition switch and mag- netic switchReplace. Lead wire coupler loose in place Retighten. Open-circuit between ignition switch and magnetic switchRepair. Open-circuit in pull-in coil Replace magnetic switch. Brushes are seating poorly or worn down Repair or replace.Poor sliding of plunger and/or pinion Repair. Motor not running (Operating sound of magnetic switch heard)Battery run down Recharge battery. Battery voltage too low due to battery deteriora- tionReplace battery. Loose battery cable connections Retighten. Burnt main contact point, or poor contacting action of magnetic switchReplace magnetic switch. Brushes are seating poorly or worn down Repair or replace. Weakened brush spring Replace. Burnt commutator Replace armature.Layer short-circuit of armature Replace.Crankshaft rotation obstructed Repair. Starting motor running but too slow (small torque) (If battery and wiring are satisfac- tory, inspect starting motor)Insufficient contact of magnetic switch main con- tactsReplace magnetic switch. Layer short-circuit of armature Replace. Disconnected, burnt or worn commutator Repair commutator or replace armature. Worn brushes Replace brush. Weakened brush springs Replace spring. Burnt or abnormally worn end bush Replace bush. Starting motor run- ning, but not cranking engineWorn pinion tip Replace over-running clutch. Poor sliding of over-running clutch Repair.Over-running clutch slipping Replace over-running clutch.Worn teeth of pinion gear Replace flywheel. Noise Abnormally worn bush Replace bush. Worn pinion or worn teeth of pinion gear Replace pinion or flywheel. Poor sliding of pinion (failure in return movement) Repair or replace.Worn internal or planetary gear teeth Replace.Lack of oil in each part Lubricate. Starting motor does not stop runningFused contact points of magnetic switch Replace magnetic switch. Short-circuit between turns of PRECAUTIONS under PRECAUTIONS in air bag system section before performing service on or around the air bag system components or wiring. Failure to follow WARNINGS could result in unin-tentional activation of the system or could render the system inoperative. Either of these two condi- tions may result in severe injury. Technical service work must be started at least 90 seconds after the ignition switch is turned to the “LOCK ” position and the negative cable is disconnected from the battery. Otherwise, the system may be activated by reserve energy in the Sensing and Diagnostic Module (SDM). NOTE: Starting motor varies depending on specifications, etc. Therefore, be sure to check model and speci- fication of the vehicle being serviced before replacing parts. GENERAL DESCRIPTION CRANKING CIRCUIT DIAGNOSIS DIAGNOSIS TABLE Possible symptoms due to starting system trouble would be as follows: Starting motor does not run (or runs slowly) Starting motor runs but fails to crank engine Abnormal noise is heard harness, (including starting motor switch), starting motor or engine. Do not remove motor just because starting motor does not run. Check following items and narrow down scopeof possible causes. 1) Condition of trouble 2) Tightness of battery terminals (including ground cable connection on engine side) and starting motor termi- nals 3) Discharge of battery 4) Mounting of starting motor1. Pinion drive lever 5. Plunger 9. Blank 2. Pinion & Over-running clutch 6. Magnetic switch contacts 10. A/T: Transmission range switch (shift lever switch)3. Magnetic switch 7. Pull-in coil 11. Ignition & Starter switch 4. Hold-in coil 8. Starting motor 12. Battery Condition Possible Cause Correction Motor not running (No operating sound of magnetic switch)Shift lever switch is not in P or N, or not adjusted (A/T)Shift in P or N, or adjust switch. Battery run down Recharge battery. Battery voltage too low due to battery deteriora- tionReplace battery. Poor contact in battery terminal connection Retighten or replace. Loose\n"
          ]
        },
        {
          "data": {
            "text/markdown": "**Answer:**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'data'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-e233987afafd>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"**Answer:**\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{output.data}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'data'"
          ]
        }
      ],
      "source": [
        "# prompt = \"my car is not starting\"\n",
        "# context = get_context(prompt)\n",
        "# print(context)\n",
        "# output = qa.call(prompt, context)\n",
        "# display(Markdown(f\"**Answer:**\"))\n",
        "# display(Markdown(f\"{output.data}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ItcgveuEgRR"
      },
      "outputs": [],
      "source": [
        "# !ps -ef | grep ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6puMDwoEgUB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYIukbJIEgW2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0igA-xaaEgZm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpjzanRvEgce"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJlF4G45EgfU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nFYYeZ6EgiW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjUyOC4fDRgG"
      },
      "outputs": [],
      "source": [
        "# ngrok.set_auth_token(\"2nVyRD5l0Q6YkY50VvBdlApRrp9_5n4F6k61SyZLpQoWDF2fF\")\n",
        "# public_url = ngrok.connect(5000)\n",
        "# print(f\" * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:5000\\\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mfJuiISDRi9"
      },
      "outputs": [],
      "source": [
        "# app = Flask(__name__)\n",
        "# run_with_ngrok(app)\n",
        "\n",
        "# @app.route('/chat', methods=['POST'])\n",
        "# def chat():\n",
        "#     data = request.json\n",
        "#     user_prompt = data['prompt']\n",
        "#     # Assume get_context and qa.call are defined\n",
        "#     context = get_context(user_prompt)\n",
        "#     output = qa.call(user_prompt, context)\n",
        "#     return jsonify({'response': output})\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     app.run()\n",
        "\n",
        "\n",
        "# # public_url = ngrok.connect(5000)\n",
        "# # print(f\" * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:5000\\\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8Ls4iRODRl0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g65j01etDRos"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfbMj5P7DRrj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ej96QHIvDRud"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x252d7ZVDRxS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHEO7KTtDR0P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFIGH-LVDR3B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGWqliFuDR51"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORoyYwsODR_d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tqe8i04sDSCg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCwXTFHaDSFT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}